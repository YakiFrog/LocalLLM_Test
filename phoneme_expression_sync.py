#!/usr/bin/env python3
"""
éŸ³éŸ»ãƒ™ãƒ¼ã‚¹è¡¨æƒ…åŒæœŸã‚·ã‚¹ãƒ†ãƒ 
AudioQueryã®éŸ³éŸ»ãƒ‡ãƒ¼ã‚¿ã¨è¡¨æƒ…ã‚¿ã‚°ã‚’çµ„ã¿åˆã‚ã›ã¦ç²¾å¯†ãªåŒæœŸã‚’å®Ÿç¾
"""

import asyncio
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import json

logger = logging.getLogger(__name__)

@dataclass
class PhonemeSegment:
    """éŸ³éŸ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ"""
    phoneme: str
    start_time: float
    end_time: float

@dataclass
class SyncedExpressionSegment:
    """åŒæœŸæ¸ˆã¿è¡¨æƒ…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ"""
    text: str
    expression: str
    start_time: float
    end_time: float
    phoneme_segments: List[PhonemeSegment]

class PhonemeBasedExpressionSync:
    """éŸ³éŸ»ãƒ™ãƒ¼ã‚¹è¡¨æƒ…åŒæœŸã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, expression_controller, voice_controller):
        self.expression_controller = expression_controller
        self.voice_controller = voice_controller
        self.current_expression = "neutral"
        self.is_playing = False
    
    async def create_synced_segments(self, tagged_text: str, audioquery_data: Dict) -> List[SyncedExpressionSegment]:
        """
        è¡¨æƒ…ã‚¿ã‚°ä»˜ããƒ†ã‚­ã‚¹ãƒˆã¨AudioQueryãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒæœŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
        
        Args:
            tagged_text: è¡¨æƒ…ã‚¿ã‚°ä»˜ããƒ†ã‚­ã‚¹ãƒˆ
            audioquery_data: AudioQueryã‹ã‚‰å–å¾—ã—ãŸéŸ³éŸ»ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            åŒæœŸæ¸ˆã¿è¡¨æƒ…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        try:
            from expression_parser import ExpressionParser
            parser = ExpressionParser()
            
            # è¡¨æƒ…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è§£æ
            expression_segments = parser.parse_expression_text(tagged_text)
            clean_text = parser.remove_expression_tags(tagged_text)
            
            # AudioQueryã‹ã‚‰éŸ³éŸ»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            accent_phrases = audioquery_data.get('accent_phrases', [])
            phoneme_data = self._extract_phoneme_timing(accent_phrases)
            
            # æ–‡å­—ä½ç½®ã¨éŸ³éŸ»ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
            synced_segments = self._map_expression_to_phonemes(
                expression_segments, phoneme_data, clean_text
            )
            
            return synced_segments
            
        except Exception as e:
            logger.error(f"åŒæœŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _extract_phoneme_timing(self, accent_phrases: List[Dict]) -> List[PhonemeSegment]:
        """ã‚¢ã‚¯ã‚»ãƒ³ãƒˆå¥ã‹ã‚‰éŸ³éŸ»ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æŠ½å‡º"""
        phoneme_segments = []
        current_time = 0.0
        
        for phrase in accent_phrases:
            moras = phrase.get('moras', [])
            
            for mora in moras:
                consonant = mora.get('consonant')
                vowel = mora.get('vowel')
                consonant_length = mora.get('consonant_length', 0.0)
                vowel_length = mora.get('vowel_length', 0.0)
                
                if consonant:
                    phoneme_segments.append(PhonemeSegment(
                        phoneme=consonant,
                        start_time=current_time,
                        end_time=current_time + consonant_length
                    ))
                    current_time += consonant_length
                
                if vowel:
                    phoneme_segments.append(PhonemeSegment(
                        phoneme=vowel,
                        start_time=current_time,
                        end_time=current_time + vowel_length
                    ))
                    current_time += vowel_length
            
            # ãƒãƒ¼ã‚ºæ™‚é–“
            pause_length = phrase.get('pause_mora', {}).get('vowel_length', 0.0)
            if pause_length > 0:
                phoneme_segments.append(PhonemeSegment(
                    phoneme='pau',
                    start_time=current_time,
                    end_time=current_time + pause_length
                ))
                current_time += pause_length
        
        return phoneme_segments
    
    def _map_expression_to_phonemes(self, expression_segments, phoneme_segments, clean_text) -> List[SyncedExpressionSegment]:
        """è¡¨æƒ…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨éŸ³éŸ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒƒãƒ”ãƒ³ã‚°"""
        synced_segments = []
        
        # æ–‡å­—ä½ç½®ã‹ã‚‰æ™‚é–“ä½ç½®ã¸ã®å¤‰æ›æ¯”ç‡ã‚’è¨ˆç®—
        total_chars = len(clean_text)
        total_time = phoneme_segments[-1].end_time if phoneme_segments else 1.0
        char_to_time_ratio = total_time / total_chars if total_chars > 0 else 0.1
        
        for expr_seg in expression_segments:
            # æ–‡å­—ä½ç½®ã‚’æ™‚é–“ã«å¤‰æ›ï¼ˆç°¡æ˜“çš„ï¼‰
            start_time = expr_seg.start_pos * char_to_time_ratio
            end_time = expr_seg.end_pos * char_to_time_ratio
            
            # è©²å½“ã™ã‚‹éŸ³éŸ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            related_phonemes = [
                p for p in phoneme_segments 
                if p.start_time < end_time and p.end_time > start_time
            ]
            
            synced_segments.append(SyncedExpressionSegment(
                text=expr_seg.text,
                expression=expr_seg.expression,
                start_time=start_time,
                end_time=end_time,
                phoneme_segments=related_phonemes
            ))
        
        return synced_segments
    
    async def play_with_precise_sync(self, synced_segments: List[SyncedExpressionSegment], audio_file_path: str) -> bool:
        """
        åŒæœŸæ¸ˆã¿ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ç²¾å¯†åŒæœŸå†ç”Ÿ
        
        Args:
            synced_segments: åŒæœŸæ¸ˆã¿è¡¨æƒ…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
            audio_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            æˆåŠŸ/å¤±æ•—
        """
        try:
            self.is_playing = True
            
            # éŸ³å£°å†ç”Ÿé–‹å§‹
            audio_task = asyncio.create_task(self._play_audio(audio_file_path))
            
            # è¡¨æƒ…åˆ¶å¾¡ã‚¿ã‚¹ã‚¯
            expression_task = asyncio.create_task(
                self._control_expressions_precise(synced_segments)
            )
            
            # ä¸¡æ–¹ã®ã‚¿ã‚¹ã‚¯ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            audio_result, expression_result = await asyncio.gather(
                audio_task, expression_task, return_exceptions=True
            )
            
            # çµæœãƒã‚§ãƒƒã‚¯
            if isinstance(audio_result, Exception):
                logger.error(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {audio_result}")
                return False
            
            if isinstance(expression_result, Exception):
                logger.error(f"è¡¨æƒ…åˆ¶å¾¡ã‚¨ãƒ©ãƒ¼: {expression_result}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"ç²¾å¯†åŒæœŸå†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            return False
        finally:
            self.is_playing = False
    
    async def _control_expressions_precise(self, synced_segments: List[SyncedExpressionSegment]):
        """ç²¾å¯†ãªè¡¨æƒ…åˆ¶å¾¡"""
        start_time = asyncio.get_event_loop().time()
        
        for segment in synced_segments:
            if not self.is_playing:
                break
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–‹å§‹ã¾ã§å¾…æ©Ÿ
            current_time = asyncio.get_event_loop().time() - start_time
            wait_time = segment.start_time - current_time
            
            if wait_time > 0:
                await asyncio.sleep(wait_time)
            
            # è¡¨æƒ…å¤‰æ›´
            await self._set_expression(segment.expression)
            
            logger.info(f"ç²¾å¯†åŒæœŸ - {segment.start_time:.2f}s: '{segment.text}' -> {segment.expression}")
    
    async def _play_audio(self, audio_file_path: str):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿ"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€é©åˆ‡ãªéŸ³å£°å†ç”Ÿãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ãªå®Ÿè£…
        if hasattr(self.voice_controller, 'play_audio_file'):
            await self.voice_controller.play_audio_file(audio_file_path)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‹ã‚‰å†ç”Ÿæ™‚é–“ã‚’æ¨å®š
            import os
            file_size = os.path.getsize(audio_file_path) if os.path.exists(audio_file_path) else 100000
            estimated_duration = file_size / 16000  # 16kHzæƒ³å®šã§ã®ç°¡æ˜“è¨ˆç®—
            await asyncio.sleep(estimated_duration)
    
    async def _set_expression(self, expression: str):
        """è¡¨æƒ…è¨­å®š"""
        if expression != self.current_expression:
            try:
                if hasattr(self.expression_controller, 'set_expression'):
                    result = self.expression_controller.set_expression(expression)
                    if result:
                        self.current_expression = expression
                        logger.info(f"ğŸ­ ç²¾å¯†è¡¨æƒ…å¤‰æ›´: {expression}")
            except Exception as e:
                logger.error(f"è¡¨æƒ…è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_playback(self):
        """å†ç”Ÿåœæ­¢"""
        self.is_playing = False

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
async def test_phoneme_sync():
    """éŸ³éŸ»åŒæœŸãƒ†ã‚¹ãƒˆ"""
    # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
    mock_audioquery = {
        "accent_phrases": [
            {
                "moras": [
                    {
                        "text": "ã‚³",
                        "consonant": "k",
                        "consonant_length": 0.1,
                        "vowel": "o",
                        "vowel_length": 0.2
                    },
                    {
                        "text": "ãƒ³",
                        "consonant": None,
                        "consonant_length": 0.0,
                        "vowel": "N",
                        "vowel_length": 0.15
                    }
                ],
                "pause_mora": {"vowel_length": 0.1}
            }
        ]
    }
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    tagged_text = "<happy>ã“ã‚“ã«ã¡ã¯</happy>ï¼<excited>ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—</excited>ã§ã™ã­ã€‚"
    
    # ãƒ¢ãƒƒã‚¯ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
    class MockController:
        def set_expression(self, expr):
            print(f"ğŸ­ è¡¨æƒ…: {expr}")
            return True
        
        async def play_audio_file(self, path):
            print(f"ğŸµ éŸ³å£°å†ç”Ÿ: {path}")
            await asyncio.sleep(2.0)  # 2ç§’ã®ãƒ€ãƒŸãƒ¼å†ç”Ÿ
    
    mock_expr = MockController()
    mock_voice = MockController()
    
    sync_system = PhonemeBasedExpressionSync(mock_expr, mock_voice)
    
    # åŒæœŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆ
    synced_segments = await sync_system.create_synced_segments(tagged_text, mock_audioquery)
    
    print(f"åŒæœŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(synced_segments)}")
    for i, seg in enumerate(synced_segments):
        print(f"  {i+1}: {seg.start_time:.2f}s-{seg.end_time:.2f}s '{seg.text}' -> {seg.expression}")
    
    # ç²¾å¯†åŒæœŸå†ç”Ÿãƒ†ã‚¹ãƒˆ
    await sync_system.play_with_precise_sync(synced_segments, "dummy_audio.wav")

if __name__ == "__main__":
    asyncio.run(test_phoneme_sync())